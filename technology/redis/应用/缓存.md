### 一. 性能

设计和使用缓存首先要了解服务、DB、Cache的性能情况。一般情况下:

- DB的响应是10ms级(优化充足的情况下，SQL平均耗时1ms，前提是命中了索引，并且命中了MySQL缓冲池(内存中)。如果命中索引但不命中缓冲池，且查询数据量不大，磁盘并发量不高，则大约耗时10ms(磁盘寻道)。如果这些都不满足，耗时就大了)
- 分布式缓存在ms级(主要损耗在网路)
- 进程内缓存在ns级(无损耗)。

### 二. 共识

正式开始之前，我觉得我们需要先取得以下两点的共识：

1. 缓存必须要有过期时间
2. 保证数据库跟缓存的最终一致性即可，不必追求强一致性

为什么必须要有过期时间？首先对于缓存来说，当它的命中率越高的时候，系统性能也就越好。如果某个缓存项没有过期时间，而它命中的概率又很低，这就是在浪费缓存的空间。而如果有了过期时间，且在某个缓存项经常被命中的情况下，我们可以在每次命中的时候都刷新一下它的过期时间，这样也就保证了热点数据会一直在缓存中存在，从而保证了缓存的命中率，提高了系统的性能。

设置过期时间还有一个好处，就是当数据库跟缓存出现数据不一致的情况时，这个可以作为一个最后的兜底手段。也就是说，当数据确实出现不一致的情况时，过期时间可以保证只有在出现不一致的时间点到缓存过期这段时间之内，数据库跟缓存的数据是不一致的，因此也保证了数据的最终一致性。

那么为什么不应该追求数据强一致性呢？这个主要是个权衡的问题。数据库跟缓存，以Mysql跟Redis举例，毕竟是两套系统，如果要保证强一致性，势必要引入2PC或3PC等分布式一致性协议，或者是分布式锁等等，这个在实现上是有难度的，而且一定会对性能有影响。而且如果真的对数据的一致性要求这么高，那引入缓存是否真的有必要呢？本文主要在保证最终一致性的前提下进行方案讨论。

### 三. 分布式缓存的设计模式

缓存的设计模式一般分为四种Cache aside, Read through, Write through, Write behind caching。

#### **1.Cache Aside Pattern**

Cache aside pattern是最常用的方式，其具体逻辑如下：

失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。

命中：应用程序从cache中取数据，取到后返回。

更新：先把数据存到数据库中，成功后，再让缓存失效。

#### 2.**Read/Write Through Pattern**

我们可以看到，在上面的Cache Aside套路中，我们的应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。所以，应用程序比较啰嗦。而Read/Write Through套路是把更新数据库（Repository）的操作由缓存自己代理了，所以，对于应用层来说，就简单很多了。可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。

Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的

Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）

#### 3.**Write Behind Caching Pattern**

Write Behind 又叫 Write Back。在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存），因为异步，write back还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（Unix/Linux非正常关机会导致数据丢失，也是因为这个事）。在软件设计上，基本上不可能做出一个没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性性是有冲突的。软件设计从来都是取舍。

另外，Write Back实现逻辑比较复杂，因为需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。



### 四. 数据库和缓存的读写顺序

实际业务开发中基本都是采用的Cache Aside Pattern。该模式的两步跟数据读取顺序有关，我觉得大家对这样的设计应该都没有异议。读数据的时候当然要优先从缓存中读取，读不到当然要从数据库中读取，然后还要放到缓存中，否则下次请求过来还得从数据库中读取。关键问题在于第三点，也就是数据更新流程，为什么要先更新数据库？为什么之后要删除缓存而不是更新？

数据更新的流程总共有四种选项：

 先更新缓存，再更新数据库

 先更新数据库，再更新缓存

 先删除缓存，再更新数据库

 先更新数据库，再删除缓存

我们来逐个分析下：

#### 1. 先更新缓存，再更新数据库

不管是操作数据库还是操作缓存，都有失败的可能。如果我们先更新缓存，再更新数据库，假设更新数据库失败了，那数据库中就存的是老数据。当然你可以选择重试更新数据库，那么再极端点，负责更新数据库的机器也宕机了，那么数据库中的数据将一直得不到更新，并且当缓存失效之后，其他机器再从数据库中读到的数据是老数据，然后再放到缓存中，这就导致先前的更新操作被丢失了，因此这么做的隐患是很大的。从数据持久化的角度来说，数据库当然要比缓存做的好，我们也应当以数据库中的数据为主，所以需要更新数据的时候我们应当首先更新数据库，而不是缓存。

#### 2. 新更新数据库，再更新缓存

这里主要有两个问题：

首先是并发的问题：假设线程A（或者机器A，道理是一样的）和线程B需要更新同一个数据，A先于B但时间间隔很短，那么就有可能会出现：

(1) 线程A更新了数据库

(2) 线程B更新了数据库

(3) 线程B更新了缓存

(4) 线程A更新了缓存

按理说线程B应该最后更新缓存，但是可能因为网络等原因，导致线程B先于线程A对缓存进行了更新，这就导致缓存中的数据不是最新的。

第二个问题是，我们不确定要更新的这个缓存项是否会被经常读取，假设每次更新数据库都会导致缓存的更新，有可能数据还没有被读取过就已经再次更新了，这就造成了缓存空间的浪费。另外，缓存中的值可能是经过一系列计算的，而并不是直接跟数据库中的数据对应的，频繁更新缓存会导致大量无效的计算，造成机器性能的浪费。

综上所述，更新缓存这一方案是不可取的，我们应当考虑删除缓存。

#### 3. 先删除缓存，再更新数据库

这个方案的问题也是很明显的，假设现在有两个请求，一个是写请求A，一个是读请求B，那么可能出现如下的执行序列：

(1) 请求A删除缓存

(2) 请求B读取缓存，发现不存在，从数据库中读取到旧值

(3) 请求A将新值写入数据库

(4) 请求B将旧值写入缓存

这样就会导致缓存中存的还是旧值，在缓存过期之前都无法读到新值。这个问题在数据库读写分离的情况下会更明显，因为主从同步需要时间，请求B获取到的数据很可能还是旧值，那么写入缓存中的也会是旧值。

#### 4. 先更新数据库，再删除缓存

这是最常用的方案，但是最常用并不是说就一定不会有任何问题，我们依然假设有两个请求，请求A是查询请求，请求B是更新请求，那么可能会出现下述情形：

(1) 先前缓存刚好失效

(2) 请求A查数据库，得到旧值

(3) 请求B更新数据库

(4) 请求B删除缓存

(5) 请求A将旧值写入缓存

上述情况确实有可能出现，但是出现的概率不高，因为上述情形成立的条件是在读取数据时，缓存刚好失效，并且此时正好又有一个并发的写请求。考虑到数据库上的写操作一般都会比读操作要慢(在写数据库时，数据库一般都会上锁，而普通的查询语句是不会上锁的。当然，复杂的查询语句除外，但是这种语句的占比不会太高)，可以合理认为在现实生活中，读请求的比例要远高于写请求。

因此我们可以得出结论：这种情况下缓存中存在脏数据的可能性是不高的。

那如果是读写分离的场景下呢？如果按照如下所述的执行序列，一样会出问题：

(1) 请求A更新主库

(2) 请求A删除缓存

(3) 请求B查询缓存，没有命中，查询从库得到旧值

(4) 从库同步完毕

(5) 请求B将旧值写入缓存

如果数据库主从同步比较慢的话，同样会出现数据不一致的问题。事实上就是如此，毕竟我们操作的是两个系统，在高并发的场景下，很难去保证多个请求之间的执行顺序，或者就算做到了，也可能会在性能上付出极大的代价。那为什么我们还是应当采用先更新数据库，再删除缓存这个策略呢？

首先，为什么要删除而不是更新缓存，这个在前面有分析，这里不再赘述。

那为什么我们应当先更新数据库呢？因为缓存在数据持久化这方面往往没有数据库做得好，而且数据库中的数据是不存在过期这个概念的，我们应当以数据库中的数据为主，缓存因为有着过期时间这一概念，最终一定会跟数据库保持一致。

#### 5. 有没有更好的办法?

在讨论最后一个方案时，我们没有考虑操作数据库或者操作缓存可能失败的情况，而这种情况也是客观存在的。那么在这里我们简单讨论下，首先是如果更新数据库失败了，其实没有太大关系，因为此时数据库和缓存中都还是老数据，不存在不一致的问题。假设删除缓存失败了呢？此时确实会存在数据不一致的情况。除了设置缓存过期时间这种兜底方案之外，如果我们希望尽可能保证缓存可以被及时删除，那么我们必须要考虑对删除操作进行重试。

首先可以直接在代码中对删除操作进行重试，但是要知道如果是网络原因导致的失败，立刻进行重试操作很可能也是失败的，因此在每次重试之间可能需要等待一段时间，比如几百毫秒甚至是秒级等待。为了不影响主流程的正常运行，还可能会将这个事情交给一个异步线程或者协程来执行，但是如果机器此时也宕机了，这个删除操作也就丢失了。

那要怎么解决这个问题呢？首先可以考虑引入消息队列，当然写入消息队列一样可能会失败，但是这是建立在缓存跟消息队列都不可用的情况下，应该说这样的概率是不高的。引入消息队列之后，就由消费端负责删除缓存以及重试，可能会慢一些但是可以保证操作不会丢失。

### 五. 缓存引入的问题

缓存系统一定程度上极大提升系统并发能力，但同样也增加额外技术考虑因素，比如缓存雪崩、缓存穿透、缓存击穿等。

#### 缓存雪崩

缓存雪崩是指缓存系统失效，导致大量请求同时进行数据回源，导致数据源压力骤增而崩溃。此种情况一般是由于多个缓存数据同时失效导致的，针对该问题，可以将缓存时间离散化，根据缓存数据访问规律和缓存数据不一致的敏感性要求来选择缓存时间

#### 缓存穿透

缓存穿透是指查询的key不存在，从而缓存查询不到而查询了数据库。若是这样的key恰好并发请求很大，那么就会对数据库造成不必要的压力。比如黑客用一堆不存在的key访问数据，大量请求发送到数据库，数据库压力过大而宕机，怎么解决呢?

1、把所有存在的key都存到另外一个存储的Set集合里，查询时可以先查询key是否存在;

2、将这些key对应的值设置为null 丢到缓存里面去。后面再出现查询这个key 的请求的时候，直接返回null，再根据业务需求设置过期时间。

3、BloomFilter 类似于一个hbase set 用来判断某个元素（key）是否存在于某个集合中。这种方式在大数据场景应用比较多，比如 Hbase 中使用它去判断数据是否在磁盘上。这种方案可以加在第1/2种方案中，在缓存之前加一层 BloomFilter ，在查询的时候先去 BloomFilter 去查询 key 是否存在，如果不存在就直接返回，存在再走查缓存 -> 查 DB。

#### 缓存击穿

在高并发的系统中，大量的请求同时查询一个 key 时(热点key)，这个key刚好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿。造成缓存击穿的原因是多个线程同时去查询数据库，那么我们可以在第一个查询数据的请求上使用一个 互斥锁。其他的线程进入等待状态，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。这个是单机场景，如果有多台机器同时去访问同一个缓存项该怎么办呢？如果机器数不是很多的话，这种情况一般来说也不会成为一个问题。不过这里有个优化点，就是从数据库读取到数据之后，再对缓存做一次判断，如果缓存中已经存在数据，就不需要再写一遍缓存了。但是如果机器数也很多的话，那么就得考虑上分布式锁了。此方案的问题是显而易见的，加锁尤其是加分布式锁会对系统性能有重大影响，而且分布式锁的实现非常考验开发者的经验和实力，在高并发场景下这一点显得尤为重要，因此我建议，不到万不得已的情况下，不要盲目上分布式锁。